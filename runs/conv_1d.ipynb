{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras.utils import plot_model\n",
    "import scipy.stats as stats\n",
    "import os \n",
    "import h5py\n",
    "import sys\n",
    "import re\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "dataset = h5py.File('./../../../../../data/hongtao/variables_tt_re2.h5','r')\n",
    "\n",
    "X_keys = ['j1_pt', 'j1_eta', 'j1_phi', 'j1_m', 'j1_DL1r', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_m', 'j2_DL1r', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_m', 'j3_DL1r', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_m', 'j4_DL1r', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_m', 'j5_DL1r', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_m', 'j6_DL1r', 'lep_pt', 'lep_eta', 'lep_phi', 'met_met', 'met_phi'] \n",
    "Y_keys = ['th_pt', 'th_eta','th_phi', 'tl_pt', 'tl_eta', 'tl_phi', 'wl_pt', 'wl_eta', 'wl_phi']\n",
    "phi_keys = ['j1_phi', 'j2_phi', 'j3_phi','j4_phi','j5_phi','j6_phi', 'lep_phi', 'met_phi', 'th_phi', 'tl_phi', 'wl_phi']\n",
    "eta_keys = ['j1_eta', 'j2_eta', 'j3_eta', 'j4_eta', 'j5_eta', 'j5_phi', 'j6_eta', 'lep_eta', 'th_eta', 'tl_eta', 'wl_eta']\n",
    "pt_keys = ['j1_pt', 'j2_pt','j3_pt','j4_pt','j5_pt','j6_pt','lep_pt','th_pt', 'tl_pt', 'wl_pt']\n",
    "m_keys = ['j1_m','j2_m', 'j3_m', 'j4_m', 'j5_m', 'j6_m', 'wl_m']\n",
    "DL1r_keys = ['j1_DL1r','j2_DL1r','j3_DL1r','j4_DL1r','j5_DL1r','j6_DL1r']\n",
    "\n",
    "Y_length = len(Y_keys)\n",
    "X_length = len(X_keys)\n",
    "crop0 =  100000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max scaling error: 7.958078640513122e-13\n"
     ]
    }
   ],
   "source": [
    "import scale_variables\n",
    "\n",
    "# How to scale each input/output\n",
    "def get_methods(keys):\n",
    "    types = {'pt':'boxcox', 'eta':'meanmax', 'phi':'linear_sincos', 'DL1r':'meanmax', 'm':'divmax', 'met':'meanmax'}\n",
    "    var_types = [key.split('_')[1] for key in keys]\n",
    "    methods = [types[var] for var in var_types]\n",
    "    return methods\n",
    "\n",
    "X_methods = get_methods(X_keys)\n",
    "Y_methods = get_methods(Y_keys)\n",
    "\n",
    "Scaler = scale_variables.Scale_variables()\n",
    "(X_total, X_maxmean), X_names = Scaler.scale_arrays(X_keys, X_methods, True)\n",
    "(Y_total, Y_maxmean), Y_names = Scaler.scale_arrays(Y_keys, Y_methods, True)\n",
    "\n",
    "error = Scaler.test_inverse(X_keys, X_methods, True)\n",
    "print('Max scaling error: {}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 6, 6) (80000, 7) (80000, 12)\n",
      "(20000, 6, 6) (20000, 7) (20000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create X and test array\n",
    "split = int(np.floor(0.8*crop0)) # 80/20 split \n",
    "shuffle = False\n",
    "\n",
    "if shuffle:\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(X_total)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(Y_total)\n",
    "\n",
    "trainX, testX = X_total[0:split, :], X_total[split:,:]\n",
    "trainY, testY = Y_total[0:split,:], Y_total[split:,:]\n",
    "\n",
    "timestep_builder = scale_variables.Shape_timesteps()\n",
    "trainX_jets, trainX_other = timestep_builder.reshape_X(trainX, X_names, False)\n",
    "testX_jets, testX_other = timestep_builder.reshape_X(testX, X_names, False)\n",
    "# mask = timestep_builder.create_mask()\n",
    "\n",
    "# Save some memory \n",
    "del trainX\n",
    "del testX \n",
    "\n",
    "print(trainX_jets.shape, trainX_other.shape, trainY.shape)\n",
    "print(testX_jets.shape, testX_other.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of Y variables \n",
    "show = False\n",
    "\n",
    "if show:\n",
    "    plt.figure(figsize=(6,6*Y_total.shape[1]))\n",
    "    for i in range(0, Y_total.shape[1]):\n",
    "        plt.subplot(Y_total.shape[1], 1, i+1)\n",
    "        plt.hist(Y_total[:,i], 20, histtype='step')\n",
    "        plt.xlabel(Y_names[i])\n",
    "        plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of X variables \n",
    "show = False\n",
    "\n",
    "if show:\n",
    "    plt.figure(figsize=(6,6*X_total.shape[1]))\n",
    "    for i in range(0, X_total.shape[1]):\n",
    "        plt.subplot(X_total.shape[1], 1, i+1)\n",
    "        plt.hist(X_total[:,i], 20, histtype='step')\n",
    "        plt.xlabel(X_names[i])\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 6, 6)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           256         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4, 32)        608         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 160)          0           flatten_3[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          20608       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           780         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 30,508\n",
      "Trainable params: 30,508\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "\n",
    "def build_model():\n",
    "    jet_input = layers.Input(shape=(trainX_jets.shape[1], trainX_jets.shape[2]))\n",
    "    Conv11 = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(jet_input)\n",
    "    flat_jets = layers.Flatten()(Conv11)\n",
    "    \n",
    "    other_input = layers.Input(shape=(trainX_other.shape[1]))\n",
    "    Dense21 = layers.Dense(32, activation='relu')(other_input)\n",
    "    flat_other = layers.Flatten()(Dense21)\n",
    "    \n",
    "    concat = layers.concatenate([flat_other, flat_jets])\n",
    "    dense1 = layers.Dense(128, activation='relu')(concat)\n",
    "    dense2 = layers.Dense(64, activation='relu')(dense1)\n",
    "    output = layers.Dense(len(Y_names), activation='linear')(dense2)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[jet_input, other_input], outputs=output)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-6)\n",
    "    model.compile(loss='mse', optimizer= optimizer, metrics=['mse'])\n",
    "    \n",
    "    return model \n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 16000 samples\n",
      "Epoch 1/2048\n",
      "  512/64000 [..............................] - ETA: 1:01WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model_1/conv1d_1/conv1d (defined at /home/hongtao/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_2161]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3573ff36aa83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m history = model.fit([trainX_jets, trainX_other], trainY, verbose=1, epochs=Epochs, \n\u001b[1;32m      8\u001b[0m                    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                    batch_size=512)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/miniconda3/envs/top-ml/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model_1/conv1d_1/conv1d (defined at /home/hongtao/miniconda3/envs/top-ml/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_2161]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "Epochs= 2048\n",
    "\n",
    "history = model.fit([trainX_jets, trainX_other], trainY, verbose=1, epochs=Epochs, \n",
    "                   validation_split=0.2, shuffle=False, callbacks=[callback],\n",
    "                   batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'], label='training')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mse loss')\n",
    "plt.legend()\n",
    "plt.title('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training \n",
    "crop = 100 \n",
    "\n",
    "train_small = model.predict(trainX[0:100,:])\n",
    "Y_small = trainY[0:100,:]\n",
    "\n",
    "\n",
    "def comparison_plot(compare, true):\n",
    "    plt.figure(figsize=(8,8*len(Y_names)))\n",
    "    for i in range(0,len(Y_names)):\n",
    "        plt.subplot(len(Y_names),1,i+1)\n",
    "        plt.plot(range(0,crop), compare[:,i], 'bo', markersize=3, label = 'Predictions')\n",
    "        plt.plot(range(0,crop), true[:,i], 'ro', markersize=3, label = 'True Value')\n",
    "        ym, yM = plt.ylim()\n",
    "        for x in range(100):\n",
    "            plt.vlines(x, color='g', linestyle='-', alpha=0.2, ymin= \n",
    "                        min(compare[x,i], true[x,i]), \n",
    "                        ymax= max(compare[x,i], true[x,i]))\n",
    "        plt.hlines(np.mean(true[:,i]), xmin=-20, xmax=crop+20, alpha=0.5)\n",
    "        MSE = 1/compare[:,i].size*np.sum((compare[:,i]- true[:,i])**2)\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel(Y_names[i])\n",
    "        plt.xlim(0, crop)\n",
    "        plt.title(Y_names[i] + \" MSE: \" + str(MSE))\n",
    "        plt.legend()\n",
    "\n",
    "comparison_plot(train_small, Y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "predictions_small = predictions[0:100,:]\n",
    "testY_small = testY[0:100,:]\n",
    "\n",
    "MSE = 1/predictions.size*np.sum((predictions- testY)**2)\n",
    "print(\"total MSE: \" + str(MSE))\n",
    "\n",
    "for i in range(Y_length):\n",
    "    MSE = 1/predictions[:,i].size*np.sum((predictions[:,i] -testY[:,i])**2)\n",
    "    print(\"{0} MSE : \".format(Y_names[i]), '%.10f'%MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscaled Histograms \n",
    "\n",
    "plt.figure(figsize=(8,8*len(Y_names)))\n",
    "for i in range(len(Y_names)):\n",
    "    plt.subplot(len(Y_names), 1, i+1)\n",
    "    hist0, bin_edges = np.histogram(testY[:, i], bins=40)\n",
    "    plt.hist(testY[:,i], bin_edges, histtype='step', color='b', label='true values', density=True)\n",
    "    plt.hist(predictions[:,i], bin_edges, histtype='step', color='r', label='predictions', density=True)\n",
    "    plt.xlabel(Y_names[i] +\" \" +str(np.max(predictions[:,i])) + \" \" + str(np.min(predictions[:,i])))\n",
    "    plt.legend()\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True - Predicted \n",
    "\n",
    "plt.figure(figsize=(8,8*len(Y_names)))\n",
    "for i in range(len(Y_names)):\n",
    "    plt.subplot(len(Y_names), 1, i+1)\n",
    "    diff = testY[:,i] - predictions[:,i]\n",
    "    hist0, bin_edges = np.histogram(testY[:, i], bins=40)\n",
    "    plt.hist(diff, bin_edges, histtype='step', color='purple', label='true - predicted', density=True)\n",
    "    plt.xlabel(\"Mean: {0}, Std: {1}\".format(np.mean(diff), np.std(diff)))\n",
    "    plt.title(Y_names[i])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_total, TO_maxmean0), _ = Scaler.scale_arrays(Y_keys, Y_methods, True)\n",
    "out_scaled = Scaler.invscale_arrays(Y_keys, Y_total, _, Y_methods, TO_maxmean0)[split:,:]\n",
    "\n",
    "total_predictions = model.predict(X_total)\n",
    "predict_scaled = Scaler.invscale_arrays(Y_keys, total_predictions, _, Y_methods, TO_maxmean0)[split:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histograms to the original scale \n",
    "\n",
    "plt.figure(figsize=(8,8*Y_length))\n",
    "for i in range(len(Y_keys)):\n",
    "    plt.subplot(Y_length, 1, i+1)\n",
    "    # hist0, bin_edges = np.histogram(out_scaled[:, i], bins=20)\n",
    "    hist, edges = np.histogram(out_scaled[:, i], 40)\n",
    "    plt.hist(out_scaled[:, i], edges, histtype='step', color='b', label='true values', density=True)\n",
    "    plt.hist(predict_scaled[:, i], edges, histtype='step', color='r', label='predictions', density=True)\n",
    "    plt.xlabel(Y_keys[i])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True - Predicted \n",
    "\n",
    "plt.figure(figsize=(8,8*Y_length))\n",
    "for i in range(len(Y_keys)):\n",
    "    plt.subplot(Y_length, 1, i+1)\n",
    "    diff = testY[:,i] - predictions[:,i]\n",
    "    hist0, bin_edges = np.histogram(testY[:, i], bins=40)\n",
    "    plt.hist(diff, bin_edges, histtype='step', color='purple', label='true - predicted', density=True)\n",
    "    plt.xlabel(\"Mean: {0}, Std: {1}\".format(np.mean(diff), np.std(diff)))\n",
    "    plt.title(Y_keys[i])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference value histograms \n",
    "plt.figure(figsize=(8,8*Y_length))\n",
    "for i in range(len(Y_keys)):\n",
    "    plt.subplot(Y_length, 1, i+1)\n",
    "    # hist0, bin_edges = np.histogram(out_scaled[:, i], bins=20)\n",
    "    diff = -predict_scaled[:, i]+out_scaled[:, i]\n",
    "    plt.hist(diff, 40, histtype='step', color='purple', label='True - Predicted', density=True)\n",
    "    plt.xlabel(\"Mean: {0}, Std: {1}\".format(np.mean(diff), np.std(diff)))\n",
    "    plt.title(Y_keys[i])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Y_length):\n",
    "    if Y_keys[i].split(\"_\")[1] == 'phi':\n",
    "        mod_pi = (predict_scaled[:,i] - out_scaled[:,i]) % (2*np.pi)\n",
    "        mod_pi = mod_pi - 2*np.pi*(mod_pi > np.pi)\n",
    "        MSE = 1/predict_scaled[:,i].size*np.sum((mod_pi)**2)\n",
    "    else:\n",
    "        MSE = 1/predict_scaled[:,i].size*np.sum((predict_scaled[:,i] - out_scaled[:,i])**2)\n",
    "    print(\"Original Scale {0} MSE : \".format(Y_keys[i]), '%.10f'%MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8*Y_length))\n",
    "for i in range(Y_length):\n",
    "    plt.subplot(Y_length, 1, i+1)\n",
    "    # hist0, bin_edges = np.histogram(out_scaled[:, i], bins=20)\n",
    "    plt.plot(out_scaled[:, i], predict_scaled[:, i]-out_scaled[:, i], 'o', color='purple', label='True - Predicted', markersize=2)\n",
    "    plt.xlabel('True: ' + Y_keys[i])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
