{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Input, concatenate, Masking, LSTM, TimeDistributed, Lambda, Reshape, Multiply\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras import initializers\n",
    "import h5py \n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "dataset = h5py.File('./../../../../../data/hongtao/variables_tt_re2.h5','r')\n",
    "\n",
    "X_keys = ['j1_pt', 'j1_eta', 'j1_phi', 'j1_m', 'j1_DL1r', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_m', 'j2_DL1r', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_m', 'j3_DL1r', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_m', 'j4_DL1r', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_m', 'j5_DL1r', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_m', 'j6_DL1r', 'lep_pt', 'lep_eta', 'lep_phi', 'met_met', 'met_phi']\n",
    "Y_keys = ['bh_pt', 'bh_eta', 'bh_phi', 'bh_m', 'bl_pt', 'bl_eta', 'bl_phi', 'bl_m']\n",
    "# 'th_pt', 'th_eta','th_phi','th_m', 'tl_pt', 'tl_eta', 'tl_phi', 'tl_m'\n",
    "phi_keys = list(filter(lambda a: 'phi' in a, dataset.keys()))\n",
    "eta_keys = list(filter(lambda a: 'eta' in a, dataset.keys()))\n",
    "pt_keys =  list(filter(lambda a: 'pt' in a, dataset.keys()))\n",
    "m_keys = list(filter(lambda a: 'm' in a, dataset.keys()))\n",
    "DL1r_keys = list(filter(lambda a: 'DL1r' in a, dataset.keys()))\n",
    "\n",
    "Y_length = len(Y_keys)\n",
    "X_length = len(X_keys)\n",
    "crop0 =  4000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scale_variables\n",
    "import shape_timesteps\n",
    "\n",
    "# How to scale each input/output\n",
    "def get_methods(keys):\n",
    "    types = {'pt':'cart_pt', 'eta':'meanmax', 'phi':'sincos', 'DL1r':'meanmax', 'm':'meanmax', 'met':'meanmax'}\n",
    "    var_types = [key.split('_')[1] for key in keys]\n",
    "    methods = [types[var] for var in var_types]\n",
    "    return methods\n",
    "\n",
    "X_methods = get_methods(X_keys)\n",
    "Y_methods = get_methods(Y_keys)\n",
    "\n",
    "Scaler = scale_variables.Scale_variables()\n",
    "(X_total, X_maxmean), X_names = Scaler.scale_arrays(X_keys, X_methods, True)\n",
    "(Y_total, Y_maxmean), Y_names = Scaler.scale_arrays(Y_keys, Y_methods, True)\n",
    "\n",
    "error = Scaler.test_inverse(Y_keys, Y_methods, True)\n",
    "print('Max scaling error: {}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and test array\n",
    "split = int(np.floor(0.95*crop0)) # 80/20 split \n",
    "\n",
    "trainY, testY = Y_total[0:split,:], Y_total[split:,:]\n",
    "\n",
    "timestep_builder = shape_timesteps.Shape_timesteps()\n",
    "totalX_jets, totalX_other = timestep_builder.reshape_X(X_total, X_names, False,True)\n",
    "\n",
    "    \n",
    "    \n",
    "trainX_jets, testX_jets = totalX_jets[0:split,:,:], totalX_jets[split:,:,:]\n",
    "trainX_other, testX_other = totalX_other[0:split,:], totalX_other[split:,:]\n",
    "\n",
    "# Save some memory \n",
    "del totalX_jets\n",
    "del totalX_other \n",
    "\n",
    "print(trainX_jets.shape, trainX_other.shape, trainY.shape)\n",
    "print(testX_jets.shape, testX_other.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of total  Y variables \n",
    "show = False\n",
    "\n",
    "other_bins = np.linspace(-1, 1, 40)\n",
    "phi_bins = np.linspace(-0.1, 0.1, 40)\n",
    "pt_bins = np.linspace(-0.3, 1, 40)\n",
    "Y_bins = [phi_bins if 'phi' in name else pt_bins if 'pt' in name else other_bins for name in Y_names]\n",
    "\n",
    "if show:\n",
    "    plt.figure(figsize=(6,6*trainY.shape[1]))\n",
    "    for i in range(0, trainY.shape[1]):\n",
    "        plt.subplot(trainY.shape[1], 1, i+1)\n",
    "        bins = Y_bins[i]\n",
    "        plt.hist(Y_total[:,i], bins, histtype='step')\n",
    "        plt.xlabel(Y_names[i])\n",
    "        plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of X variables (without the mask)\n",
    "show = False\n",
    "\n",
    "if show:\n",
    "    plt.figure(figsize=(6,6*X_total.shape[1]))\n",
    "    for i in range(0, X_total.shape[1]):\n",
    "        plt.subplot(X_total.shape[1], 1, i+1)\n",
    "        plt.hist(X_total[:,i], 40, histtype='step')\n",
    "        plt.xlabel(X_names[i])\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_pt = np.array(dataset.get('th_pt'))[0:crop0]\n",
    "hist1, bins = np.histogram(th_pt, 40)\n",
    "hist1 = hist1 + (hist1<=0)*1\n",
    "bins[-1] = np.inf\n",
    "plt.hist(th_pt, 40, histtype='step', label='original')\n",
    "argright = 8\n",
    "argleft = 2\n",
    "right = bins[argright]\n",
    "left = bins[argleft]\n",
    "compare_min = hist1[argright-1]\n",
    "plt.axvline(x=left, color='r', linestyle='--')\n",
    "plt.axvline(x=right, color='r', linestyle='--')\n",
    "flat = 1\n",
    "belong = np.digitize(th_pt, bins) - 1\n",
    "factor = compare_min/hist1*(hist1>=compare_min) + (hist1<compare_min)\n",
    "weight = factor[belong]\n",
    "plt.hist(th_pt, bins, histtype='step', label='reweighted', color='g', weights=weight)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Dtrain = xgb.DMatrix(trainX, label=trainY)\n",
    "Dtest = xgb.DMatrix(testX, label=testY)\n",
    "\n",
    "model = sklearn.multioutput.MultiOutputRegressor(xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.1, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_unscaled = model.predict([testX_jets, testX_other])\n",
    "true_unscaled = testY \n",
    "\n",
    "total_predictions = model.predict([np.append(trainX_jets,testX_jets,axis=0), np.append(trainX_other,testX_other,axis=0)])\n",
    "(Y_total, TO_maxmean0), _ = Scaler.scale_arrays(Y_keys, Y_methods, True)\n",
    "\n",
    "predictions_origscale = Scaler.invscale_arrays(Y_keys, total_predictions, _, Y_methods, TO_maxmean0)[split:,:]\n",
    "true_origscale = Scaler.invscale_arrays(Y_keys, Y_total, _, Y_methods, TO_maxmean0)[split:,:]\n",
    "\n",
    "del Y_total\n",
    "del TO_maxmean0\n",
    "del _\n",
    "del total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('predict_blamb.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training scale plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis\n",
    "import importlib\n",
    "importlib.reload(analysis)\n",
    "Analysis = analysis.Analysis \n",
    "Analysis.display_errors(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.predictions_vs_sample(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.variable_histogram(predictions_unscaled, true_unscaled, Y_names, False, Y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis.difference_histogram(predictions_unscaled, true_unscaled, Y_names, False, Y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Analysis.predicted_vs_true(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.predicted_vs_true_hist1(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    " # Original scale plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.display_errors(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.predictions_vs_sample(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.variable_histogram(predictions_origscale, true_origscale, Y_keys, True, [None for name in Y_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Analysis.predicted_vs_true(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.predicted_vs_true_hist1(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import observables \n",
    "import importlib\n",
    "\n",
    "importlib.reload(observables)\n",
    "truths = observables.fill_observables(true_origscale, True, Y_keys)\n",
    "preds = observables.fill_observables(predictions_origscale, False, Y_keys)\n",
    "\n",
    "# top_dphi=np.abs(th_phi-tl_phi)\n",
    "plt.figure(figsize=(12,6))\n",
    "observables.plot_hist(truths['top_dphi'], preds['top_dphi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# top_m0= th_m**2-th_p**2 + tl_m**2-tl_p**2\n",
    "plt.figure(figsize=(12,6))\n",
    "observables.plot_hist(truths['top_m0'],preds['top_m0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta_cm=0.5*(th_eta-tl_eta), eta_boost=0.5*(th_eta+tl_eta)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "observables.plot_hist(truths['eta_cm'], preds['eta_cm'])\n",
    "plt.subplot(212)\n",
    "observables.plot_hist(truths['eta_boost'], preds['eta_boost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# th_Pout=dot(th_P, cross(tl_P,ez)/norm(tl_P,ez)), tl_Pout=dot(tl_P, cross(th_P,ez)/norm(th_P,ez))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "observables.plot_hist(truths['th_Pout'], preds['th_Pout'])\n",
    "plt.subplot(212)\n",
    "observables.plot_hist(truths['tl_Pout'], preds['tl_Pout'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_tot = th_pt+tl_pt\n",
    "plt.figure(figsize=(12,6))\n",
    "observables.plot_hist(truths['pt_tot'],preds['pt_tot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
