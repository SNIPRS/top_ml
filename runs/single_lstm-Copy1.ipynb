{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM boxcox lambda = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Input, concatenate, Masking, LSTM, TimeDistributed, Bidirectional, RepeatVector\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras import initializers\n",
    "import h5py \n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "dataset = h5py.File('./../../../../../data/hongtao/variables_tt_re2.h5','r')\n",
    "\n",
    "X_keys = ['j1_pt', 'j1_eta', 'j1_phi', 'j1_m', 'j1_DL1r', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_m', 'j2_DL1r', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_m', 'j3_DL1r', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_m', 'j4_DL1r', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_m', 'j5_DL1r', 'lep_pt', 'lep_eta', 'lep_phi', 'met_met', 'met_phi']\n",
    "Y_keys = ['th_pt', 'th_eta','th_phi', 'tl_pt', 'tl_eta', 'tl_phi', 'wh_pt', 'wh_eta', 'wh_phi', 'wl_pt', 'wl_eta', 'wl_phi', 'bh_pt','bh_eta', 'bh_phi','bl_pt','bl_eta', 'bl_phi']\n",
    "phi_keys = list(filter(lambda a: 'phi' in a, dataset.keys()))\n",
    "eta_keys = list(filter(lambda a: 'eta' in a, dataset.keys()))\n",
    "pt_keys =  list(filter(lambda a: 'pt' in a, dataset.keys()))\n",
    "m_keys = list(filter(lambda a: 'm' in a, dataset.keys()))\n",
    "DL1r_keys = list(filter(lambda a: 'DL1r' in a, dataset.keys()))\n",
    "\n",
    "\n",
    "Y_length = len(Y_keys)\n",
    "X_length = len(X_keys)\n",
    "crop0 =  200000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max scaling error: 3.410605131648481e-13\n"
     ]
    }
   ],
   "source": [
    "import scale_variables\n",
    "import shape_timesteps\n",
    "\n",
    "# How to scale each input/output\n",
    "def get_methods(keys):\n",
    "    types = {'pt':'cartbox', 'eta':'meanmax', 'phi':'phi_pi', 'DL1r':'meanmax', 'm':'meanmax', 'met':'meanmax'}\n",
    "    var_types = [key.split('_')[1] for key in keys]\n",
    "    methods = [types[var] for var in var_types]\n",
    "    return methods\n",
    "\n",
    "X_methods = get_methods(X_keys)\n",
    "Y_methods = get_methods(Y_keys)\n",
    "\n",
    "Scaler = scale_variables.Scale_variables()\n",
    "(X_total, X_maxmean), X_names = Scaler.scale_arrays(X_keys, X_methods, True)\n",
    "(Y_total, Y_maxmean), Y_names = Scaler.scale_arrays(Y_keys, Y_methods, True)\n",
    "\n",
    "error = Scaler.test_inverse(Y_keys, Y_methods, True)\n",
    "print('Max scaling error: {}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 6, 5) (160000, 6, 3)\n",
      "(40000, 6, 5) (40000, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create X and test array\n",
    "split = int(np.floor(0.8*crop0)) # 80/20 split \n",
    "\n",
    "trainY, testY = Y_total[0:split,:], Y_total[split:,:]\n",
    "\n",
    "timestep_builder = shape_timesteps.Shape_timesteps()\n",
    "totalX_jets, totalX_other = timestep_builder.reshape_X(X_total, X_names, True,True)\n",
    "\n",
    "mask = timestep_builder.create_mask()\n",
    "totalX_jets = mask*totalX_jets - 2*(1-mask)\n",
    "trainX_jets, testX_jets = totalX_jets[0:split,:,:], totalX_jets[split:,:,:]\n",
    "trainX_other, testX_other = totalX_other[0:split,:], totalX_other[split:,:]\n",
    "\n",
    "trainX_other = np.reshape(trainX_other, (trainX_other.shape[0], 1, -1))\n",
    "testX_other = np.reshape(testX_other, (testX_other.shape[0], 1, -1))\n",
    "trainX = np.concatenate([trainX_other, trainX_jets], axis=1)\n",
    "testX = np.concatenate([testX_other, testX_jets], axis=1)\n",
    "trainY = np.split(trainY, 6, axis=1)\n",
    "trainY = np.stack(trainY, axis=1)\n",
    "testY = np.split(testY, 6, axis=1)\n",
    "testY = np.stack(testY, axis=1)\n",
    "# Save some memory \n",
    "del totalX_jets\n",
    "del totalX_other \n",
    "\n",
    "print(trainX.shape, trainY.shape)\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of total  Y variables \n",
    "show = False\n",
    "\n",
    "other_bins = np.linspace(-1, 1, 40)\n",
    "phi_bins = np.linspace(-0.1, 0.1, 40)\n",
    "pt_bins = np.linspace(-0.3, 1, 40)\n",
    "Y_bins = [phi_bins if 'phi' in name else pt_bins if 'pt' in name else other_bins for name in Y_names]\n",
    "\n",
    "if show:\n",
    "    plt.figure(figsize=(6,6*Y_total.shape[1]))\n",
    "    for i in range(0, Y_total.shape[1]):\n",
    "        plt.subplot(Y_total.shape[1], 1, i+1)\n",
    "        bins = Y_bins[i]\n",
    "        plt.hist(Y_total[:,i], bins, histtype='step')\n",
    "        plt.xlabel(Y_names[i])\n",
    "        plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of X variables (without the mask)\n",
    "show = False\n",
    "\n",
    "if show:\n",
    "    plt.figure(figsize=(6,6*X_total.shape[1]))\n",
    "    for i in range(0, X_total.shape[1]):\n",
    "        plt.subplot(X_total.shape[1], 1, i+1)\n",
    "        plt.hist(X_total[:,i], 40, histtype='step')\n",
    "        plt.xlabel(X_names[i])\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6, 5)]            0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 6, 5)              0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 6, 440)            2640      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 6, 176)            372416    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 6, 176)            186560    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 6, 176)            186560    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 6, 320)            56640     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 6, 90)             28890     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 6, 30)             2730      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 6, 3)              93        \n",
      "=================================================================\n",
      "Total params: 836,529\n",
      "Trainable params: 836,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "\n",
    "def build_model():\n",
    "    In = Input(shape=(trainX.shape[1], trainX.shape[2]))\n",
    "    Mask = Masking(-2)(In)\n",
    "    TD1 = TimeDistributed(Dense(440, activation='relu'))(Mask)\n",
    "    LSTM1 = Bidirectional(LSTM(88, return_sequences=True))(TD1)\n",
    "    LSTM2 = Bidirectional(LSTM(88, return_sequences=True))(LSTM1)\n",
    "    LSTM3 = Bidirectional(LSTM(88, return_sequences=True))(LSTM2)\n",
    "    TD2 = TimeDistributed(Dense(320, activation='relu'))(LSTM3)\n",
    "    TD3 = TimeDistributed(Dense(90, activation='relu'))(TD2)\n",
    "    TD4 = TimeDistributed(Dense(30, activation='relu'))(TD3)\n",
    "    TD5 = TimeDistributed(Dense(trainY.shape[2], activation='linear'))(TD4)\n",
    "    model = keras.models.Model(inputs=[In], outputs=TD5)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    model.compile(loss='mse', optimizer= optimizer, metrics=['mse'])\n",
    "    \n",
    "    return model \n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='mse', patience=10)\n",
    "\n",
    "Epochs= 256\n",
    "\n",
    "# del X_total\n",
    "# del Y_total\n",
    "\n",
    "history = model.fit([trainX], trainY, verbose=1, epochs=Epochs, \n",
    "                   validation_split=0.2, shuffle=False,\n",
    "                   batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'], label='training')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mse loss')\n",
    "plt.legend()\n",
    "plt.title('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis:\n",
    "    def __init__(self):\n",
    "        self.crop = 100\n",
    "        self.fsize = 6\n",
    "        self.histogram_bins = 40\n",
    "        \n",
    "    def wrap_phi(self, var):\n",
    "        var = var%(2*np.pi)\n",
    "        var = var - 2*np.pi*(var > np.pi)\n",
    "        return var\n",
    "        \n",
    "    def predictions_vs_sample(self, compare, true, names, wrap_phi):\n",
    "        plt.figure(figsize=(self.fsize*2, self.fsize*len(names)))\n",
    "        for i in range(0, len(names)):\n",
    "            compare_small = compare[:self.crop,i]\n",
    "            true_small = true[:self.crop,i]\n",
    "            if wrap_phi and \"phi\" in names[i]:\n",
    "                compare_small = self.wrap_phi(compare_small)\n",
    "                true_small = self.wrap_phi(true_small)\n",
    "            plt.subplot(len(names), 1, i+1)\n",
    "            plt.plot(range(0,self.crop), compare_small, 'bo', markersize=3, label = 'Predictions')\n",
    "            plt.plot(range(0,self.crop), true_small, 'ro', markersize=3, label = 'True Value')\n",
    "            ym, yM = plt.ylim()\n",
    "            for x in range(self.crop):\n",
    "                plt.vlines(x, color='g', linestyle='-', alpha=0.2, ymin= \n",
    "                            min(compare_small[x], true_small[x]), \n",
    "                            ymax= max(compare_small[x], true_small[x]))\n",
    "            plt.hlines(np.mean(true[:,i]), xmin=-20, xmax=self.crop+20, alpha=0.5)\n",
    "            MSE = 1/compare[:,i].size*np.sum((compare[:,i]- true[:,i])**2)\n",
    "            plt.xlabel('Sample')\n",
    "            plt.xlim(0, self.crop)\n",
    "            plt.ylabel(names[i])\n",
    "            plt.title(names[i] + \" MSE: \" + str(MSE))\n",
    "            plt.legend()\n",
    "    \n",
    "    def display_errors(self, compare, true, names, wrap_phi):\n",
    "        MSE = 1/compare.size*np.sum((compare- true)**2)\n",
    "        print(\"total MSE: \" + str(MSE))\n",
    "        print(\" \")\n",
    "        for i in range(len(names)):\n",
    "            diff = compare[:,i] -true[:,i]\n",
    "            if wrap_phi and \"phi\" in names[i]:\n",
    "                diff = self.wrap_phi(diff)\n",
    "            MSE = 1/compare[:,i].size*np.sum((diff)**2)\n",
    "            print(\"{0} MSE : \".format(names[i]), '%.10f'%MSE)\n",
    "    \n",
    "    def difference_histogram(self, compare, true, names, wrap_phi, bins):\n",
    "        plt.figure(figsize=(self.fsize*2,self.fsize*len(names)))\n",
    "        for i in range(len(names)):\n",
    "            plt.subplot(len(names), 1, i+1)\n",
    "            diff = true[:,i] - compare[:,i]\n",
    "            hist0, bin_edges = np.histogram(true[:, i], bins=40)\n",
    "            if bins[i] is None:\n",
    "                hbins = bin_edges\n",
    "            else:\n",
    "                hbins = bins[i]\n",
    "            plt.hist(diff, hbins, histtype='step', color='purple', label='true - predicted', density=True)\n",
    "            plt.xlabel(\"Difference (Mean: {0}, Std: {1})\".format(np.mean(diff), np.std(diff)))\n",
    "            plt.title(names[i])\n",
    "            plt.legend()\n",
    "            plt.ylabel('Frequency')\n",
    "            \n",
    "    def variable_histogram(self, compare, true, names, wrap_phi, bins): \n",
    "        plt.figure(figsize=(self.fsize*2,self.fsize*len(names)))\n",
    "        for i in range(len(names)):\n",
    "            plt.subplot(len(names), 1, i+1)\n",
    "            compare_small = compare[:, i]\n",
    "            true_small = true[:, i]\n",
    "            if wrap_phi and \"phi\" in names[i]:\n",
    "                compare_small = self.wrap_phi(compare_small)\n",
    "                true_small = self.wrap_phi(true_small)\n",
    "            hist0, bin_edges = np.histogram(true[:, i], bins=40)\n",
    "            \n",
    "            if bins[i] is None:\n",
    "                hbins = bin_edges\n",
    "            else:\n",
    "                hbins = bins[i]\n",
    "                \n",
    "            plt.hist(true_small, hbins, histtype='step', color='b', label='true values', density=False)\n",
    "            plt.hist(compare_small, hbins, histtype='step', color='r', label='predictions', density=False)\n",
    "            plt.xlabel(names[i])\n",
    "            plt.title(names[i])\n",
    "            plt.legend()\n",
    "            plt.ylabel('Frequency')\n",
    "    \n",
    "    def difference_vs_variable(self, compare, true, names, wrap_phi):\n",
    "        plt.figure(figsize=(self.fsize*2,self.fsize*len(names)))\n",
    "        for i in range(len(names)):\n",
    "            plt.subplot(len(names), 1, i+1)\n",
    "            plt.plot(true[:, i], true[:, i]-compare[:, i], 'o', color='purple', label='True - Predicted', markersize=2)\n",
    "            plt.xlabel('True ' + names[i])\n",
    "            plt.legend()\n",
    "            plt.ylabel('Difference')\n",
    "    \n",
    "    def predicted_vs_true(self, compare, true, names, wrap_phi):\n",
    "        plt.figure(figsize=(self.fsize*2,self.fsize*len(names)))\n",
    "        for i in range(len(names)):\n",
    "            plt.subplot(len(names), 1, i+1)\n",
    "            plt.plot(true[:, i], compare[:, i], 'o', color='g', markersize=2)\n",
    "            line = np.linspace(np.min(true[:, i]), np.max(true[:, i]), 100)\n",
    "            plt.plot(line, line, color='b')\n",
    "            plt.xlabel('True')\n",
    "            plt.title(names[i])\n",
    "            plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = Analysis()\n",
    "\n",
    "predictions_unscaled = model.predict([testX])\n",
    "true_unscaled = testY.reshape((testY.shape[0], -1))\n",
    "predictions_unscaled = predictions_unscaled.reshape((predictions_unscaled.shape[0], -1))\n",
    "\n",
    "total_predictions = model.predict([np.append(trainX,testX,axis=0)])\n",
    "total_predictions = total_predictions.reshape((total_predictions.shape[0], -1))\n",
    "(Y_total, TO_maxmean0), _ = Scaler.scale_arrays(Y_keys, Y_methods, True)\n",
    "\n",
    "predictions_origscale = Scaler.invscale_arrays(Y_keys, total_predictions, _, Y_methods, TO_maxmean0)[split:,:]\n",
    "true_origscale = Scaler.invscale_arrays(Y_keys, Y_total, _, Y_methods, TO_maxmean0)[split:,:]\n",
    "\n",
    "del Y_total\n",
    "del TO_maxmean0\n",
    "del _\n",
    "del total_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training scale plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display.display_errors(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.predictions_vs_sample(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display.variable_histogram(predictions_unscaled, true_unscaled, Y_names, False, Y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.difference_histogram(predictions_unscaled, true_unscaled, Y_names, False, Y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display.predicted_vs_true(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    " # Original scale plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display_errors(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.predictions_vs_sample(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display.variable_histogram(predictions_origscale, true_origscale, Y_keys, True, [None for name in Y_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display.predicted_vs_true(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[3].get_weights()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
